{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "KEY = config.get('AWS','KEY')\n",
    "SECRET = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_DB = config.get('DWH', 'DWH_DB')\n",
    "DWH_DB_USER = config.get('DWH', 'DWH_DB_USER')\n",
    "DWH_DB_PASSWORD = config.get('DWH', 'DWH_DB_PASSWORD')\n",
    "DWH_PORT = config.get('DWH', 'DWH_PORT')\n",
    "DWH_ROLE_ARN = config.get('DWH', 'DWH_ROLE_ARN')\n",
    "DWH_ENDPOINT = config.get('DWH', 'DWH_ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postgresql://username:password@host:port/database\n",
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT, DWH_DB)\n",
    "\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to S3 bucket and read files using prefix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3',\n",
    "                   region_name='us-east-2', # replace with your cluster region\n",
    "                   aws_access_key_id=KEY,\n",
    "                   aws_secret_access_key=SECRET)\n",
    "\n",
    "DbBucket = s3.Bucket(\"dwh-training\")\n",
    "\n",
    "#view data files\n",
    "for song_obj in DbBucket.objects.filter(Prefix=\"data/song_data/A/\"):\n",
    "    print(song_obj)\n",
    "\n",
    "for log_obj in DbBucket.objects.filter(Prefix=\"data/log_data/2018/11/\"):\n",
    "    print(log_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create staging tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS staging_event;\n",
    "DROP TABLE IF EXISTS staging_song;\n",
    "\n",
    "SET search_path TO public;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS staging_event(\n",
    "    artist VARCHAR,\n",
    "    auth VARCHAR,\n",
    "    firstName VARCHAR,\n",
    "    gender TEXT,\n",
    "    itemInSession INTEGER,\n",
    "    lastName VARCHAR,\n",
    "    length FLOAT,\n",
    "    level TEXT,\n",
    "    location VARCHAR,\n",
    "    method TEXT,\n",
    "    page TEXT,\n",
    "    registration FLOAT,\n",
    "    sessionId INTEGER,\n",
    "    song VARCHAR,\n",
    "    status INTEGER,\n",
    "    ts BIGINT,\n",
    "    userAgent VARCHAR,\n",
    "    userId VARCHAR\n",
    "    );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS staging_song(\n",
    "    num_songs INTEGER,\n",
    "    artist_id VARCHAR(100),\n",
    "    artist_latitude FLOAT,\n",
    "    artist_longitude FLOAT,\n",
    "    artist_location VARCHAR(100),\n",
    "    artist_name VARCHAR(100),\n",
    "    song_id VARCHAR(50),\n",
    "    title VARCHAR(100),\n",
    "    duration FLOAT,\n",
    "    year INTEGER\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert into staging tables using the COPY command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_staging_event = (\"\"\"COPY staging_event FROM 's3://dwh-training/data/log_data/2018/11/'\n",
    "    credentials 'aws_iam_role={}' region 'us-east-2' \n",
    "    JSON 's3://dwh-training/data/log_jsonpath.json';\"\"\").format(DWH_ROLE_ARN)\n",
    "\n",
    "copy_staging_song = (\"\"\"COPY staging_song FROM 's3://dwh-training/data/song_data/A/'\n",
    "    credentials 'aws_iam_role={}' region 'us-east-2' JSON 'auto';\"\"\").format(DWH_ROLE_ARN) \n",
    "\n",
    "%sql $copy_staging_event\n",
    "%sql $copy_staging_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Fact and Dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SET search_path TO project;\n",
    "\n",
    "DROP TABLE IF EXISTS songplays;\n",
    "DROP TABLE IF EXISTS users;\n",
    "DROP TABLE IF EXISTS songs;\n",
    "DROP TABLE IF EXISTS artists;\n",
    "DROP TABLE IF EXISTS time;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS songplays (\n",
    "    songplay_id INTEGER IDENTITY(1, 1) PRIMARY KEY,\n",
    "    start_time bigint NOT NULL REFERENCES time(start_time) sortkey,\n",
    "    user_id VARCHAR NOT NULL REFERENCES users(user_id),\n",
    "    level TEXT,\n",
    "    song_id varchar(50) NOT NULL REFERENCES songs(song_id) distkey,\n",
    "    artist_id varchar(100) NOT NULL REFERENCES artists(artist_id),\n",
    "    session_id INTEGER NOT NULL,\n",
    "    location varchar(200),\n",
    "    user_agent varchar(225));\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "    user_id varchar(50) PRIMARY KEY,\n",
    "    first_name varchar(50),\n",
    "    last_name varchar(50),\n",
    "    gender TEXT,\n",
    "    level TEXT)\n",
    "    DISTSTYLE all;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS songs (\n",
    "    song_id varchar(50) PRIMARY KEY,\n",
    "    title varchar(100),\n",
    "    artist_id varchar(100) REFERENCES artists(artist_id) sortkey distkey,\n",
    "    year INTEGER,\n",
    "    duration FLOAT);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS artists (\n",
    "    artist_id varchar(100) PRIMARY KEY,\n",
    "    name varchar(100),\n",
    "    location varchar(100),\n",
    "    latitude float,\n",
    "    longitude float)\n",
    "    DISTSTYLE all;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS time (\n",
    "    start_time bigint PRIMARY KEY,\n",
    "    hour INTEGER,\n",
    "    day INTEGER,\n",
    "    week INTEGER,\n",
    "    month INTEGER,\n",
    "    year INTEGER,\n",
    "    weekday INTEGER)\n",
    "    DISTSTYLE all;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert into fact and dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO users (\n",
    "    user_id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    gender,\n",
    "    level) \n",
    "SELECT userId AS user_id, firstName AS first_name,\n",
    "lastName AS last_name, gender, level\n",
    "FROM public.staging_event\n",
    "WHERE userId IS NOT NULL\n",
    "ORDER BY user_id;\n",
    "\n",
    "\n",
    "INSERT INTO songs(\n",
    "    song_id,\n",
    "    title,\n",
    "    artist_id,\n",
    "    year,\n",
    "    duration) \n",
    "SELECT song_id, title, artist_id, year, duration\n",
    "FROM public.staging_song\n",
    "ORDER BY song_id;\n",
    "\n",
    "\n",
    "INSERT INTO artists (\n",
    "    artist_id,\n",
    "    name,\n",
    "    location,\n",
    "    latitude,\n",
    "    longitude)\n",
    "SELECT artist_id, artist_name, artist_location AS location,\n",
    "artist_latitude AS latitude, artist_longitude AS longitude\n",
    "FROM public.staging_song\n",
    "WHERE artist_name IS NOT NULL\n",
    "ORDER BY artist_id;\n",
    "\n",
    "\n",
    "INSERT INTO time (\n",
    "    start_time,\n",
    "    hour,\n",
    "    day,\n",
    "    week,\n",
    "    month,\n",
    "    year,\n",
    "    weekday)\n",
    "SELECT start_time,\n",
    "    EXTRACT(hour FROM date_time) AS hour,\n",
    "    EXTRACT(day FROM date_time) AS day,\n",
    "    EXTRACT(week FROM date_time) AS week,\n",
    "    EXTRACT(month FROM date_time) AS month,\n",
    "    EXTRACT(year FROM date_time) AS year,\n",
    "    EXTRACT(weekday FROM date_time) AS weekday\n",
    "FROM (SELECT ts AS start_time,\n",
    "    CAST('1900-01-01' AS DATE) + ts/1000 * interval '1 sec' AS date_time\n",
    "    FROM public.staging_event)\n",
    "ORDER BY start_time;\n",
    "\n",
    "\n",
    "INSERT INTO songplays (\n",
    "    start_time,\n",
    "    user_id,\n",
    "    level,\n",
    "    song_id,\n",
    "    artist_id,\n",
    "    session_id,\n",
    "    location,\n",
    "    user_agent) \n",
    "SELECT SE.ts AS start_time,\n",
    "SE.userId AS user_id,\n",
    "SE.level,\n",
    "SS.song_id,\n",
    "SS.artist_id,\n",
    "SE.sessionId AS session_id,\n",
    "SE.location,\n",
    "SE.userAgent AS user_agent\n",
    "FROM public.staging_event SE\n",
    "JOIN public.staging_song SS ON SE.song = SS.title\n",
    "AND SE.artist = SS.artist_name\n",
    "LEFT OUTER JOIN songplays ON SE.userId = songplays.user_id\n",
    "AND SE.ts = songplays.start_time\n",
    "WHERE SE.page = 'NextSong'\n",
    "AND SE.userId IS NOT NULL\n",
    "AND SE.level IS NOT NULL\n",
    "AND SS.song_id IS NOT NULL\n",
    "AND SS.artist_id IS NOT NULL\n",
    "AND SE.sessionId IS NOT NULL\n",
    "AND SE.location IS NOT NULL\n",
    "AND SE.userAgent IS NOT NULL\n",
    "ORDER BY start_time, user_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytics from the Fact & Dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select artist_id, count(songplay_id) as count_songplays\n",
    "from songplays\n",
    "group by artist_id\n",
    "order by count_songplays desc\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT s.title || ',\\n' || a.name as song_artist, count(songplay_id) count_songplays\n",
    "FROM songplays sp\n",
    "LEFT JOIN songs s\n",
    "ON sp.song_id = s.song_id\n",
    "LEFT JOIN artists a\n",
    "ON s.artist_id = a.artist_id\n",
    "GROUP BY song_artist\n",
    "ORDER BY count_songplays desc\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "query2 = %sql $query2\n",
    "df2 = pd.DataFrame(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "plt.barh(df2[0], df2[1], zorder=2)\n",
    "plt.title('Most played song')\n",
    "plt.grid(True)\n",
    "plt.xlabel('number of times')\n",
    "plt.ylabel('Songs played')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT t.hour,\n",
    "       COUNT(s.songplay_id) AS count_songplays\n",
    "  FROM songplays s\n",
    "  LEFT JOIN time t\n",
    "    ON s.start_time = t.start_time\n",
    " group by hour\n",
    " order by hour;\"\"\"\n",
    "\n",
    "query = %sql $query\n",
    "df = pd.DataFrame(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "plt.bar(df[0], df[1], zorder=2)\n",
    "plt.title('Songplays by hour')\n",
    "plt.grid(True)\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('plays')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select a.name,\n",
    "       temp.count_songplays\n",
    "  from (select artist_id,\n",
    "               count(songplay_id) as count_songplays\n",
    "          from project.songplays\n",
    "         group by artist_id) as temp\n",
    "  left join project.artists a\n",
    "    on temp.artist_id = a.artist_id\n",
    " order by temp.count_songplays desc\n",
    " limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download a file from S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "\n",
    "BUCKET_NAME = 'udacity-dend' # this is your bucket name\n",
    "FILENAME = 'log_json_path.json' # this is the file you want to download\n",
    "OUT_AS = 'JSONPath.json' # this is what you wish to save the downloaded file as\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name='us-west-2',\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "try:\n",
    "    s3.Bucket(BUCKET_NAME).download_file(FILENAME, OUT_AS)\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == \"404\":\n",
    "        print(\"The object does not exist.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download a folder from S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name='us-west-2',\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET)\n",
    "\n",
    "DbBucket = s3.Bucket(\"udacity-dend\")\n",
    "\n",
    "for song_obj in DbBucket.objects.filter(Prefix=\"song_data/A/\"):\n",
    "    if not os.path.exists(os.path.dirname(song_obj.key)):\n",
    "        os.makedirs(os.path.dirname(song_obj.key))\n",
    "    DbBucket.download_file(song_obj.key, song_obj.key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save UNLOAD(ed) csv formatted files with .csv extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name='us-east-2',\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET)\n",
    "\n",
    "DbBucket = s3.Bucket(\"dwh-training\")\n",
    "\n",
    "fileDir = DbBucket.objects.filter(Prefix=\"unload/\")\n",
    "\n",
    "#first rename the files\n",
    "for obj in FileDir:\n",
    "    new_name = obj.key + \".csv\"\n",
    "    s3.Object(obj.bucket_name, new_name).copy_from(CopySource=(obj.bucket_name + '/' + obj.key))\n",
    "    s3.Object(obj.bucket_name, obj.key).delete()\n",
    "    print(new_name)\n",
    "    \n",
    "#then download the files rectory\n",
    "for obj in fileDir:\n",
    "    if not os.path.exists(os.path.dirname(obj.key)):\n",
    "        os.makedirs(os.path.dirname(obj.key))\n",
    "    print(\"Now downloading \", obj.key, \" ...\")\n",
    "    DbBucket.download_file(obj.key, obj.key)\n",
    "print(\"Download completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
