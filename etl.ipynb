{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "KEY = config.get('AWS','KEY')\n",
    "SECRET = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_DB = config.get('DWH', 'DWH_DB')\n",
    "DWH_DB_USER = config.get('DWH', 'DWH_DB_USER')\n",
    "DWH_DB_PASSWORD = config.get('DWH', 'DWH_DB_PASSWORD')\n",
    "DWH_PORT = config.get('DWH', 'DWH_PORT')\n",
    "DWH_ROLE_ARN = config.get('DWH', 'DWH_ROLE_ARN')\n",
    "DWH_ENDPOINT = config.get('DWH', 'DWH_ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postgresql://username:password@host:port/database\n",
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT, DWH_DB)\n",
    "\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to S3 bucket and view files using prefix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3',\n",
    "                   region_name='us-east-2', # replace with your cluster region\n",
    "                   aws_access_key_id=KEY,\n",
    "                   aws_secret_access_key=SECRET)\n",
    "\n",
    "DbBucket = s3.Bucket(\"dwh-training\")\n",
    "\n",
    "#view data files\n",
    "for song_obj in DbBucket.objects.filter(Prefix=\"data/song_data/A/\"):\n",
    "    print(song_obj)\n",
    "\n",
    "for log_obj in DbBucket.objects.filter(Prefix=\"data/log_data/2018/11/\"):\n",
    "    print(log_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create staging tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS staging_event;\n",
    "DROP TABLE IF EXISTS staging_song;\n",
    "\n",
    "SET search_path TO public;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS staging_event(\n",
    "    artist VARCHAR,\n",
    "    auth VARCHAR,\n",
    "    firstName VARCHAR,\n",
    "    gender TEXT,\n",
    "    itemInSession INTEGER,\n",
    "    lastName VARCHAR,\n",
    "    length FLOAT,\n",
    "    level TEXT,\n",
    "    location VARCHAR,\n",
    "    method TEXT,\n",
    "    page TEXT,\n",
    "    registration FLOAT,\n",
    "    sessionId INTEGER,\n",
    "    song VARCHAR,\n",
    "    status INTEGER,\n",
    "    ts BIGINT,\n",
    "    userAgent VARCHAR,\n",
    "    userId VARCHAR\n",
    "    );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS staging_song(\n",
    "    num_songs INTEGER,\n",
    "    artist_id VARCHAR(100),\n",
    "    artist_latitude FLOAT,\n",
    "    artist_longitude FLOAT,\n",
    "    artist_location VARCHAR(100),\n",
    "    artist_name VARCHAR(100),\n",
    "    song_id VARCHAR(50),\n",
    "    title VARCHAR(100),\n",
    "    duration FLOAT,\n",
    "    year INTEGER\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert into staging tables using the COPY command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_staging_event = (\"\"\"COPY staging_event FROM 's3://dwh-training/data/log_data/2018/11/'\n",
    "    credentials 'aws_iam_role={}' region 'us-east-2' \n",
    "    JSON 's3://dwh-training/data/log_jsonpath.json';\"\"\").format(DWH_ROLE_ARN)\n",
    "\n",
    "copy_staging_song = (\"\"\"COPY staging_song FROM 's3://dwh-training/data/song_data/A/'\n",
    "    credentials 'aws_iam_role={}' region 'us-east-2' JSON 'auto';\"\"\").format(DWH_ROLE_ARN) \n",
    "\n",
    "%sql $copy_staging_event\n",
    "%sql $copy_staging_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Fact and Dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SET search_path TO project;\n",
    "\n",
    "DROP TABLE IF EXISTS songplays;\n",
    "DROP TABLE IF EXISTS users;\n",
    "DROP TABLE IF EXISTS songs;\n",
    "DROP TABLE IF EXISTS artists;\n",
    "DROP TABLE IF EXISTS time;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS songplays (\n",
    "    songplay_id INTEGER IDENTITY(1, 1) PRIMARY KEY,\n",
    "    start_time bigint NOT NULL REFERENCES time(start_time) sortkey,\n",
    "    user_id VARCHAR NOT NULL REFERENCES users(user_id),\n",
    "    level TEXT,\n",
    "    song_id varchar(50) NOT NULL REFERENCES songs(song_id) distkey,\n",
    "    artist_id varchar(100) NOT NULL REFERENCES artists(artist_id),\n",
    "    session_id INTEGER NOT NULL,\n",
    "    location varchar(200),\n",
    "    user_agent varchar(225));\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "    user_id varchar(50) PRIMARY KEY,\n",
    "    first_name varchar(50),\n",
    "    last_name varchar(50),\n",
    "    gender TEXT,\n",
    "    level TEXT)\n",
    "    DISTSTYLE all;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS songs (\n",
    "    song_id varchar(50) PRIMARY KEY,\n",
    "    title varchar(100),\n",
    "    artist_id varchar(100) REFERENCES artists(artist_id) sortkey distkey,\n",
    "    year INTEGER,\n",
    "    duration FLOAT);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS artists (\n",
    "    artist_id varchar(100) PRIMARY KEY,\n",
    "    name varchar(100),\n",
    "    location varchar(100),\n",
    "    latitude float,\n",
    "    longitude float)\n",
    "    DISTSTYLE all;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS time (\n",
    "    start_time bigint PRIMARY KEY,\n",
    "    hour INTEGER,\n",
    "    day INTEGER,\n",
    "    week INTEGER,\n",
    "    month INTEGER,\n",
    "    year INTEGER,\n",
    "    weekday INTEGER)\n",
    "    DISTSTYLE all;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert into fact and dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO users (\n",
    "    user_id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    gender,\n",
    "    level) \n",
    "SELECT userId AS user_id, firstName AS first_name,\n",
    "lastName AS last_name, gender, level\n",
    "FROM public.staging_event\n",
    "WHERE userId IS NOT NULL\n",
    "ORDER BY user_id;\n",
    "\n",
    "\n",
    "INSERT INTO songs(\n",
    "    song_id,\n",
    "    title,\n",
    "    artist_id,\n",
    "    year,\n",
    "    duration) \n",
    "SELECT song_id, title, artist_id, year, duration\n",
    "FROM public.staging_song\n",
    "ORDER BY song_id;\n",
    "\n",
    "\n",
    "INSERT INTO artists (\n",
    "    artist_id,\n",
    "    name,\n",
    "    location,\n",
    "    latitude,\n",
    "    longitude)\n",
    "SELECT artist_id, artist_name, artist_location AS location,\n",
    "artist_latitude AS latitude, artist_longitude AS longitude\n",
    "FROM public.staging_song\n",
    "WHERE artist_name IS NOT NULL\n",
    "ORDER BY artist_id;\n",
    "\n",
    "\n",
    "INSERT INTO time (\n",
    "    start_time,\n",
    "    hour,\n",
    "    day,\n",
    "    week,\n",
    "    month,\n",
    "    year,\n",
    "    weekday)\n",
    "SELECT start_time,\n",
    "    EXTRACT(hour FROM date_time) AS hour,\n",
    "    EXTRACT(day FROM date_time) AS day,\n",
    "    EXTRACT(week FROM date_time) AS week,\n",
    "    EXTRACT(month FROM date_time) AS month,\n",
    "    EXTRACT(year FROM date_time) AS year,\n",
    "    EXTRACT(weekday FROM date_time) AS weekday\n",
    "FROM (SELECT ts AS start_time,\n",
    "    CAST('1900-01-01' AS DATE) + ts/1000 * interval '1 sec' AS date_time\n",
    "    FROM public.staging_event)\n",
    "ORDER BY start_time;\n",
    "\n",
    "\n",
    "INSERT INTO songplays (\n",
    "    start_time,\n",
    "    user_id,\n",
    "    level,\n",
    "    song_id,\n",
    "    artist_id,\n",
    "    session_id,\n",
    "    location,\n",
    "    user_agent) \n",
    "SELECT SE.ts AS start_time,\n",
    "SE.userId AS user_id,\n",
    "SE.level,\n",
    "SS.song_id,\n",
    "SS.artist_id,\n",
    "SE.sessionId AS session_id,\n",
    "SE.location,\n",
    "SE.userAgent AS user_agent\n",
    "FROM public.staging_event SE\n",
    "JOIN public.staging_song SS ON SE.song = SS.title\n",
    "AND SE.artist = SS.artist_name\n",
    "LEFT OUTER JOIN songplays ON SE.userId = songplays.user_id\n",
    "AND SE.ts = songplays.start_time\n",
    "WHERE SE.page = 'NextSong'\n",
    "AND SE.userId IS NOT NULL\n",
    "AND SE.level IS NOT NULL\n",
    "AND SS.song_id IS NOT NULL\n",
    "AND SS.artist_id IS NOT NULL\n",
    "AND SE.sessionId IS NOT NULL\n",
    "AND SE.location IS NOT NULL\n",
    "AND SE.userAgent IS NOT NULL\n",
    "ORDER BY start_time, user_id;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
